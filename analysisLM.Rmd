---
title: "Linear models"
author: "Marta Coronado"
date: '2022-05-24'
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(MASS)
library(jtools)
library(ggplot2)
library(wesanderson)
```

## Read data

From **Appendix 1** we take  the information on `repeat`, `location`, `LT50`, `Latitude`, `Longitude`, `Dis10`, `Dis5`, `LUCAS` and `Strain` (Appendix 1).

```{r info1, eval=FALSE}
info1 <- read.table("info1.tab", header = T, sep = "\t", stringsAsFactors = T)
head(info1)
```

From **Appendix 2** we take the information on pollutants of each location, and the urban category.

```{r info2, eval=FALSE}
info2 <- read.table("info2.tab", header = T, sep = "\t", stringsAsFactors = T)
info2
```

Data is merged by `Strain`, so we create a table with 97 observations and 16 variables.

```{r merge}
#data <- merge(info1, info2, by="Strain")
#write.table(data, "dataLM.tab", col.names = T, row.names = F, sep = "\t", quote = F)
data <- read.table("dataLM.tab", header = T, sep = "\t", stringsAsFactors = T)
head(data)
```

## Linear models

LM with all variables:

```{r lm-all}
lmAll = lm(LT50  ~ Latitude + Longitude + Location +
           Dis10 + Dis50 +  
           LUCAS + PM10 + PM2.5 + 
           Arsenic + Cadium + Lead +
           UrbanCategoryF,
         data = data) 
summary(lmAll)
```

We get a warning about the coefficients: *12 not defined because of singularities*. This is because variables are correlated (correlation's coefficients are 1). This is expected because the latitude, longitude and location are the same, and the distances are also highly correlated with the urban category, as they were inferred by them. 

**So we remove the variables that are highly correlated, we have two possibilities:**

- 1. With latitude and longitude but remove the urban category:

```{r lm1a}
lm1a = lm(LT50  ~ Latitude + Longitude + Dis10 + Dis50+
                 LUCAS + PM10 + PM2.5 + 
                 Arsenic + Cadium + Lead,
               data = data) 
summary(lm1a) 
```

- 2. With urban category but removing latitude and longitude.

```{r lm1b}
lm1b = lm(LT50  ~ Dis10 + Dis50 +  
                 LUCAS + PM10 + PM2.5 + 
                 Arsenic + Cadium + Lead +
                 UrbanCategoryF,
               data = data) 
summary(lm1b) 
```

These two models take into account the maximum amount of variables while avoiding singularities. Both models are very similar and explain 19% of the variance of LT50, but they are not significant (p-values = 0.06).

### Remove variables
We want the model with only relevant variables. We can use `dropterm()` to remove variables that are not informative. The model should  be explaining the same amount of variance but only with the relevant variables.

The procedure is to remove variables 1 by 1, starting from the least significant, 

```{r lm1b-drop-term-1}
dropterm(lm1b, test = "F")
```

We first remove `Arsenic`.

```{r lm2}
lm2 = lm(LT50  ~ Dis10 + Dis50 +  
                 LUCAS + PM10 + PM2.5 + 
                 Cadium + Lead +
                 UrbanCategoryF,
               data = data) 
summary(lm2) 
```


```{r lm1b-drop-term-2}
dropterm(lm2, test = "F")
```

We remove `PM10`.

```{r lm3}
lm3 = lm(LT50  ~ Dis10 + Dis50 +  
                 LUCAS + PM2.5 + 
                 Cadium + Lead +
                 UrbanCategoryF,
               data = data) 
summary(lm3) 
```



```{r lm1b-drop-term-3}
dropterm(lm3, test = "F")
```

We remove `Dis50`.

```{r lm4}
lm4 = lm(LT50  ~ Dis10 +  
                 LUCAS + PM2.5 + 
                 Cadium + Lead +
                 UrbanCategoryF,
               data = data) 
summary(lm4) 
```


```{r lm1b-drop-term-4}
dropterm(lm4, test = "F")
```

We remove `PM2.5`.

```{r lm5}
lm5 = lm(LT50  ~ Dis10 +  
                 LUCAS + 
                 Cadium + Lead +
                 UrbanCategoryF,
               data = data) 
summary(lm5) 
```


```{r lm1b-drop-term-5}
dropterm(lm5, test = "F")
```

We remove `Cadium`.

```{r lm6}
lm6 = lm(LT50  ~ Dis10 +  
                 LUCAS + 
                 Lead +
                 UrbanCategoryF,
               data = data) 
summary(lm6) 
```


```{r lm1b-drop-term-6}
dropterm(lm6, test = "F")
```

Because now all terms are significant, it means that the relevant variables to explain LT50 are `Dis10`, `LUCAS`, `Lead` and `UrbanCategoryF`.

We explain 14% of the variance, and the p-value is 0.02. The most important variable is `LUCAS`, followed by `Urban category - Urban`. `Semi` is not significant and `Dis10` is marginally ignificant. 


### Plots


```{r plots}
plot_summs(lm6)

effect_plot(lm6, pred = LUCAS, interval = TRUE, plot.points = TRUE, 
            jitter = 0.05)
ggsave(filename = "effect_plot_LUCAS.png", plot = last_plot())

effect_plot(lm6, pred = UrbanCategoryF, interval = TRUE, plot.points = TRUE, 
            jitter = 0.05, x.label = "Urban category")
ggsave(filename = "effect_plot_UrbanCategory.png", plot = last_plot())


data$UrbanCategoryF <- factor(data$UrbanCategoryF, levels=c("Urban", "Semi","Rural"))
ggplot(data, aes(x=UrbanCategoryF, y=LT50, fill=UrbanCategoryF)) + 
                  geom_boxplot(show.legend = FALSE) + scale_fill_manual(values = wes_palette("Zissou1", type = c("continuous"))) + geom_jitter(shape=16, position=position_jitter(0.2), show.legend = FALSE) + labs(x="", y = "LT50 values") + scale_x_discrete(breaks = c("Rural", "Semi", "Urban"), labels = c("R", "SU", "U"))

 ggsave("Figure1D.pdf", width = 5)
```
